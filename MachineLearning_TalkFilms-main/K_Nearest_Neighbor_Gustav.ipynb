{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "57c00f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# general use\n",
    "import os\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import multiprocessing\n",
    "\n",
    "sns.set_theme()\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# for evaluation\n",
    "from statistics import mean\n",
    "from sklearn.metrics import f1_score ,accuracy_score, classification_report, confusion_matrix, precision_score, roc_auc_score\n",
    "from sklearn import metrics\n",
    "\n",
    "\n",
    "# for current method\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neighbors import KDTree\n",
    "from sklearn.model_selection import cross_val_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5d0126e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Default] Number of train data: 1039, Number of test data: 387\n"
     ]
    }
   ],
   "source": [
    "data_dirpath = 'dataset'\n",
    "train_name = 'train.csv'\n",
    "test_name = 'test.csv'\n",
    "\n",
    "train_path = os.path.join(data_dirpath, train_name)\n",
    "test_path = os.path.join(data_dirpath, test_name)\n",
    "X_train = pd.read_csv(train_path, header=[0])\n",
    "test_df = pd.read_csv(test_path, header=[0])\n",
    "\n",
    "print(f'[Default] Number of train data: {X_train.shape[0]}, Number of test data: {test_df.shape[0]}')\n",
    "\n",
    "\n",
    "lead_map = {'Female': 0 , 'Male': 1}\n",
    "X_train['Lead'] = X_train['Lead'].map(lead_map).astype(int)\n",
    "\n",
    "x_data=X_train.loc[:, X_train.columns != 'Lead']\n",
    "y_data=X_train['Lead']\n",
    "\n",
    "feature_names = x_data.columns.tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f7ae257d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "X_train = x_data\n",
    "y_train = y_data\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "46fa202c-af1f-4041-9abe-8e288e0f1f93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Number words female', 'Total words', 'Number of words lead',\n",
      "       'Difference in words lead and co-lead', 'Number of male actors', 'Year',\n",
      "       'Number of female actors', 'Number words male', 'Gross',\n",
      "       'Mean Age Male', 'Mean Age Female', 'Age Lead', 'Age Co-Lead'],\n",
      "      dtype='object')\n",
      "Index(['Number words female', 'Total words', 'Number of words lead',\n",
      "       'Difference in words lead and co-lead', 'Number of male actors', 'Year',\n",
      "       'Number of female actors', 'Number words male', 'Gross',\n",
      "       'Mean Age Male', 'Mean Age Female', 'Age Lead', 'Age Co-Lead',\n",
      "       'female to male ratio'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Number words female</th>\n",
       "      <th>Total words</th>\n",
       "      <th>Number of words lead</th>\n",
       "      <th>Difference in words lead and co-lead</th>\n",
       "      <th>Number of male actors</th>\n",
       "      <th>Year</th>\n",
       "      <th>Number of female actors</th>\n",
       "      <th>Number words male</th>\n",
       "      <th>Gross</th>\n",
       "      <th>Mean Age Male</th>\n",
       "      <th>...</th>\n",
       "      <th>female to male ratio</th>\n",
       "      <th>Age difference</th>\n",
       "      <th>YearXGross</th>\n",
       "      <th>words/actors female</th>\n",
       "      <th>words/actors male</th>\n",
       "      <th>Male/Female Actors Ratio</th>\n",
       "      <th>Log Male/Female Actors Ratio</th>\n",
       "      <th>Total Actors</th>\n",
       "      <th>LogGross</th>\n",
       "      <th>Lead Word Dominance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1512</td>\n",
       "      <td>6394</td>\n",
       "      <td>2251.0</td>\n",
       "      <td>343</td>\n",
       "      <td>2</td>\n",
       "      <td>1995</td>\n",
       "      <td>5</td>\n",
       "      <td>2631</td>\n",
       "      <td>142.0</td>\n",
       "      <td>51.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.739590</td>\n",
       "      <td>-19.0</td>\n",
       "      <td>-281275.0</td>\n",
       "      <td>302.40</td>\n",
       "      <td>1315.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>-0.693147</td>\n",
       "      <td>7</td>\n",
       "      <td>4.962845</td>\n",
       "      <td>0.352049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1524</td>\n",
       "      <td>8780</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>1219</td>\n",
       "      <td>9</td>\n",
       "      <td>2001</td>\n",
       "      <td>4</td>\n",
       "      <td>5236</td>\n",
       "      <td>37.0</td>\n",
       "      <td>39.125000</td>\n",
       "      <td>...</td>\n",
       "      <td>3.434098</td>\n",
       "      <td>24.0</td>\n",
       "      <td>-72022.0</td>\n",
       "      <td>381.00</td>\n",
       "      <td>581.777778</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>13</td>\n",
       "      <td>3.637586</td>\n",
       "      <td>0.230068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>155</td>\n",
       "      <td>4176</td>\n",
       "      <td>942.0</td>\n",
       "      <td>787</td>\n",
       "      <td>7</td>\n",
       "      <td>1968</td>\n",
       "      <td>1</td>\n",
       "      <td>3079</td>\n",
       "      <td>376.0</td>\n",
       "      <td>42.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>19.743590</td>\n",
       "      <td>9.0</td>\n",
       "      <td>-737953.0</td>\n",
       "      <td>155.00</td>\n",
       "      <td>439.857143</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>8</td>\n",
       "      <td>5.932245</td>\n",
       "      <td>0.225575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1073</td>\n",
       "      <td>9855</td>\n",
       "      <td>3440.0</td>\n",
       "      <td>2623</td>\n",
       "      <td>12</td>\n",
       "      <td>2002</td>\n",
       "      <td>2</td>\n",
       "      <td>5342</td>\n",
       "      <td>19.0</td>\n",
       "      <td>35.222222</td>\n",
       "      <td>...</td>\n",
       "      <td>4.974860</td>\n",
       "      <td>10.0</td>\n",
       "      <td>-36023.0</td>\n",
       "      <td>536.50</td>\n",
       "      <td>445.166667</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>1.466337</td>\n",
       "      <td>14</td>\n",
       "      <td>2.995732</td>\n",
       "      <td>0.349061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1317</td>\n",
       "      <td>7688</td>\n",
       "      <td>3835.0</td>\n",
       "      <td>3149</td>\n",
       "      <td>8</td>\n",
       "      <td>1988</td>\n",
       "      <td>4</td>\n",
       "      <td>2536</td>\n",
       "      <td>40.0</td>\n",
       "      <td>45.250000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.924886</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>-77505.0</td>\n",
       "      <td>329.25</td>\n",
       "      <td>317.000000</td>\n",
       "      <td>1.800000</td>\n",
       "      <td>0.587787</td>\n",
       "      <td>12</td>\n",
       "      <td>3.713572</td>\n",
       "      <td>0.498829</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Number words female  Total words  Number of words lead  \\\n",
       "0                 1512         6394                2251.0   \n",
       "1                 1524         8780                2020.0   \n",
       "2                  155         4176                 942.0   \n",
       "3                 1073         9855                3440.0   \n",
       "4                 1317         7688                3835.0   \n",
       "\n",
       "   Difference in words lead and co-lead  Number of male actors  Year  \\\n",
       "0                                   343                      2  1995   \n",
       "1                                  1219                      9  2001   \n",
       "2                                   787                      7  1968   \n",
       "3                                  2623                     12  2002   \n",
       "4                                  3149                      8  1988   \n",
       "\n",
       "   Number of female actors  Number words male  Gross  Mean Age Male  ...  \\\n",
       "0                        5               2631  142.0      51.500000  ...   \n",
       "1                        4               5236   37.0      39.125000  ...   \n",
       "2                        1               3079  376.0      42.500000  ...   \n",
       "3                        2               5342   19.0      35.222222  ...   \n",
       "4                        4               2536   40.0      45.250000  ...   \n",
       "\n",
       "   female to male ratio  Age difference  YearXGross  words/actors female  \\\n",
       "0              1.739590           -19.0   -281275.0               302.40   \n",
       "1              3.434098            24.0    -72022.0               381.00   \n",
       "2             19.743590             9.0   -737953.0               155.00   \n",
       "3              4.974860            10.0    -36023.0               536.50   \n",
       "4              1.924886            -3.0    -77505.0               329.25   \n",
       "\n",
       "   words/actors male  Male/Female Actors Ratio  Log Male/Female Actors Ratio  \\\n",
       "0        1315.500000                  0.500000                     -0.693147   \n",
       "1         581.777778                  2.000000                      0.693147   \n",
       "2         439.857143                  4.000000                      1.386294   \n",
       "3         445.166667                  4.333333                      1.466337   \n",
       "4         317.000000                  1.800000                      0.587787   \n",
       "\n",
       "   Total Actors  LogGross  Lead Word Dominance  \n",
       "0             7  4.962845             0.352049  \n",
       "1            13  3.637586             0.230068  \n",
       "2             8  5.932245             0.225575  \n",
       "3            14  2.995732             0.349061  \n",
       "4            12  3.713572             0.498829  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # adding features: \n",
    "# # ratio of dialog length\n",
    "#------------------------------------------------------------------------------------------\n",
    "# f2m_ratio = (X_train['Number words male']+1) /( X_train['Number words female']+1 )  \n",
    "\n",
    "# X_train['female to male ratio'] = f2m_ratio\n",
    "# print(X_train)\n",
    "\n",
    "# age_diff = f2m_ratio = X_train['Age Lead'] - X_train['Age Co-Lead'] \n",
    "# X_train['Age difference'] = age_diff\n",
    "#-------------------------------------------------------------------------\n",
    "\n",
    "#X_train = X_train.drop(columns=['Gross'])#, 'Number words male'])\n",
    "print(X_train.columns)\n",
    "#'Number words female' 'Number words male' 'Year'\n",
    "#['Number words female', 'Total words', 'Number of words lead', 'Difference in words lead and co-lead', 'Number of male actors', 'Year', 'Number of female actors', 'Number words male', 'Gross','Mean Age Male', 'Mean Age Female', 'Age Lead', 'Age Co-Lead']\n",
    "\n",
    "\n",
    "f2m_ratio = (X_train['Number words male']+1) /( X_train['Number words female']+1 )  \n",
    "\n",
    "X_train['female to male ratio'] = f2m_ratio\n",
    "print(X_train.columns)\n",
    "\n",
    "age_diff = f2m_ratio = X_train['Age Lead'] - X_train['Age Co-Lead'] \n",
    "X_train['Age difference'] = age_diff\n",
    "\n",
    "X_train[\"YearXGross\"] = (np.max(X_train[\"Year\"].values))- X_train[\"Year\"] * X_train[\"Gross\"]\n",
    "#X_train.drop(['Year', 'Gross'], axis=1, inplace=True)\n",
    "\n",
    "X_train[\"words/actors female\"] = X_train[\"Number words female\"] / X_train[\"Number of female actors\"]\n",
    "X_train[\"words/actors male\"] = X_train[\"Number words male\"] / X_train[\"Number of male actors\"]\n",
    "#X_train.drop(['Number words female', 'Number words male'], axis=1, inplace=True)\n",
    "\n",
    "X_train[\"Male/Female Actors Ratio\"] = (X_train['Number of male actors']+1) /(X_train['Number of female actors']+1)\n",
    "X_train[\"Log Male/Female Actors Ratio\"] = np.log(X_train[\"Male/Female Actors Ratio\"])\n",
    "X_train[\"Total Actors\"] = X_train['Number of male actors']+X_train['Number of female actors']\n",
    "X_train[\"LogGross\"] = np.log(X_train[\"Gross\"]+1)\n",
    "\n",
    " \n",
    "#X_train.loc[X_train['Lead'] == 1, 'Total Male Words'] = X_train['Number words male'] + X_train['Number of words lead']\n",
    "#X_train.loc[X_train['Lead'] != 1, 'Total Male Words'] = X_train['Total words'] - (X_train['Number words female'] + X_train['Number of words lead'])\n",
    "\n",
    "#X_train.loc[X_train['Lead'] == 'Female', 'Total Female Words'] = X_train['Number words female'] + X_train['Number of words lead']\n",
    "#X_train.loc[X_train['Lead'] != 'Female', 'Total Female Words'] = X_train['Total words'] - (X_train['Number words male'] + X_train['Number of words lead'])\n",
    "#X_train[\"Total Male/Female Words Ratio\"] = X_train[\"Total Male Words\"] / X_train[\"Total Female Words\"]\n",
    "\n",
    "#X_train['Words per Male Actor'] = X_train['Total Male Words'] / X_train['Number of male actors']\n",
    "#X_train['Words per Female Actor'] = X_train['Total Female Words'] / X_train['Number of female actors']\n",
    "#X_train['Log Words per Male Actor'] = np.log(X_train['Words per Male Actor'])\n",
    "#X_train['Log Words per Female Actor'] = np.log(X_train['Words per Female Actor'])\n",
    "\n",
    "#X_train['Log Total Male Words'] = np.log(X_train['Total Male Words'])\n",
    "#X_train['Log Total Female Words'] = np.log(X_train['Total Female Words'])\n",
    "#X_train[\"Log Total Male/Female Words Ratio\"] = np.log(X_train[\"Total Male/Female Words Ratio\"])\n",
    "\n",
    "X_train['Lead Word Dominance'] = X_train['Number of words lead'] / X_train['Total words']\n",
    "\n",
    "#X_train[\"Total Male Words Percentage\"] = X_train[\"Total Male Words\"]/X_train[\"Total words\"]\n",
    "#X_train[\"Total Female Words Percentage\"] = X_train[\"Total Female Words\"]/X_train[\"Total words\"]\n",
    "# X_train[\"Total Female Words Percentage\"] = 1 - X_train[\"Total Male Words Percentage\"]\n",
    "X_train.head()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2f139bb3-c0a1-489e-b105-58eadce9ccd3",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-5-4c0bea331b0c>, line 27)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-5-4c0bea331b0c>\"\u001b[1;36m, line \u001b[1;32m27\u001b[0m\n\u001b[1;33m    return train_set\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "## normalize all Data: some Data should be normalized together\n",
    "combined_normalization = [\n",
    "       ['Number words female','Number words male','Total words', 'Number of words lead','Difference in words lead and co-lead','words/actors female', 'words/actors male'],\n",
    "       ['Number of male actors','Number of female actors', 'Total Actors'],\n",
    "       ['Year'],\n",
    "       ['Gross'],\n",
    "       ['Mean Age Male', 'Mean Age Female', 'Age Lead', 'Age Co-Lead','Age difference'],\n",
    "       ['female to male ratio'], \n",
    "       ['YearXGross'], \n",
    "       ['Male/Female Actors Ratio'],\n",
    "       ['Log Male/Female Actors Ratio'],\n",
    "       [ 'LogGross'],\n",
    "       ['Lead Word Dominance']\n",
    " ]\n",
    "#combined_normalization = [ [col] for col in X_train.columns.tolist() ]\n",
    "\n",
    "def find_common_mean_norm(column_names, train_set):\n",
    "    collumn_values = []\n",
    "    for name in column_names:\n",
    "        collumn_values.append(train_set[name].values)\n",
    "    common_array = np.concatenate(collumn_values)\n",
    "    mean = np.mean(common_array)\n",
    "    norm = np.linalg.norm(common_array)\n",
    "    for name in column_names:\n",
    "        train_set[name] = (train_set[name]-np.min(collumn_values) / (np.max(collumn_values)-np.min(collumn_values))\n",
    "                           \n",
    "    return train_set\n",
    "        \n",
    "    \n",
    "for combined in combined_normalization:\n",
    "     X_train = find_common_mean_norm(combined, X_train)\n",
    "    \n",
    "X_train.head()\n",
    "    \n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31cde826-7a5d-449b-a6ba-3c36c6655426",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fcaddb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(type(X_train1))\n",
    "columns = X_train.columns\n",
    "for x in columns:\n",
    "    print(x)\n",
    "print(columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57958e05-9d62-4fa6-9d03-0c86e7fe4b03",
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "\n",
    "# looking at the available metrics\n",
    "metrics = KDTree.valid_metrics\n",
    "print(metrics)\n",
    "# ['euclidean', 'l2', 'minkowski', 'p', 'manhattan', 'cityblock', 'l1', 'chebyshev', 'infinity']\n",
    "\n",
    "\n",
    "# setting up the classifier KNN\n",
    "knn = KNeighborsClassifier()\n",
    "knn.algorithm = 'kd_tree'\n",
    "knn.metric = metrics[0]\n",
    "knn.weights ='uniform' #'distance'\n",
    "\n",
    "#knn.metric = metrics[3]\n",
    "knn.n_neighbors = 5\n",
    "knn.n_jobs = multiprocessing.cpu_count()-1\n",
    "#knn.fit(X_train,y_train)\n",
    "\n",
    "# #cross_val_score = cross_val_score(knn,X_train,y_train,crossValidationFolds = 5)\n",
    "# cvs = cross_val_score\n",
    "# cvs\n",
    "# cross_val_score.estimator = knn\n",
    "# cvs.X = X_train\n",
    "# cross_val_score.y = y_train\n",
    "# cvs.cv = 5\n",
    "# cvs.n_jobs = multiprocessing.cpu_count()-1\n",
    "# cvs.scoring = 'accuracy'\n",
    "# #cvs.scoring = classification_report\n",
    "# #cvs.scoring = roc_auc_score\n",
    "# possible_scores = ['accuracy' , 'f1' , 'roc_auc' , ]\n",
    "\n",
    "# scores = cross_val_score(estimator = cvs.estimator, X = cvs.X , y = cvs.y , cv = cvs.cv , n_jobs = cvs.n_jobs, scoring = cvs.scoring )\n",
    "\n",
    "\n",
    "# print(np.mean(scores))\n",
    "\n",
    "# print(scores)\n",
    "\n",
    "# cvs.scoring = 'f1'\n",
    "# scores = cross_val_score(estimator = cvs.estimator, X = cvs.X , y = cvs.y , cv = cvs.cv , n_jobs = cvs.n_jobs, scoring = cvs.scoring )\n",
    "# print(scores)\n",
    "\n",
    "##Dropping Features \n",
    "\n",
    "\n",
    "all_features = X_train.columns.tolist()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def evaluate_feature(feature, training_set):\n",
    "    from sklearn.model_selection import StratifiedKFold\n",
    "    # setting up the data for crossvalidation\n",
    "    X_train_restricted = training_set.drop(columns=feature) # X_train.drop(columns=feature)\n",
    "    crossValSegs = StratifiedKFold(n_splits=5,random_state = 42,shuffle = True).split(X_train_restricted,y_train)\n",
    "    crossValSegs = list(crossValSegs)\n",
    "    max_accuracy = 0\n",
    "    max_string = ''\n",
    "    max_roc_auc = 0\n",
    "    max_roc_string = ''\n",
    "    for metric in ['euclidean',  'chebyshev', 'infinity']: #[KDTree.valid_metrics]:\n",
    "       # print('\\n ------------------------------------------------------------ \\n')\n",
    "        knn.metric = metric\n",
    "        for nneighbours in   [3,4,5,9,10,11]:  # [1,2,3,4,5,7,8,9,11]:\n",
    "            accuracies = []\n",
    "            roc_aucs =  []\n",
    "            knn.n_neighbors = nneighbours\n",
    "            for train, test in crossValSegs:\n",
    "                #print(X_train_restricted.values[test],y_train.values[test])\n",
    "                knn.fit(X_train_restricted.values[train],y_train.values[train])\n",
    "                probabilities = knn.predict_proba(X_train_restricted.values[test] )\n",
    "                y_pred = knn.predict(X_train_restricted.values[test])\n",
    "               # y_pred = np.ones(len(X_train_restricted.values[test]))\n",
    "                 # evaluate\n",
    "                accuracy = accuracy_score(y_train.values[test], y_pred)\n",
    "                accuracy = f1_score(y_train.values[test], y_pred)\n",
    "                #estimator.predict_proba(X, y)[:, 1]\n",
    "                roc_auc = roc_auc_score(y_train.values[test], y_pred) #probabilities[:, 1])\n",
    "                accuracies.append(accuracy)\n",
    "                roc_aucs.append(roc_auc)\n",
    "            mean_accuracies = np.mean(accuracies)\n",
    "            mean_roc_auc = np.mean(roc_aucs)\n",
    "            current =  ' n =   {} Mean Accuracy  {} Mean ROC Auc Score   {} metric = {} Feature = {}'.format( knn.n_neighbors,mean_accuracies,  mean_roc_auc ,knn.metric, feature)\n",
    "            if mean_accuracies > max_accuracy: \n",
    "                max_accuracy = mean_accuracies\n",
    "                max_string = current\n",
    "            #print(current)\n",
    "            if mean_roc_auc > max_roc_auc: \n",
    "                max_roc_auc = mean_roc_auc\n",
    "                max_roc_string = current\n",
    "           #print(current)\n",
    "\n",
    "    print(f'\\n\\nThe Best Accuracy  Is {max_string}')\n",
    "    #print(f'\\n\\nThe Best roc_auc Is {max_roc_string}')\n",
    "    print(f'maximum accuracy {max_accuracy}')\n",
    "    return max_accuracy, max_string\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c3611d3-6998-4814-ac08-585fe92dea68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_features =  x_data.columns.tolist()\n",
    "feature_acc = []\n",
    "feature_strings = []\n",
    "for feature in all_features:\n",
    "    print(f'current Feature = {feature}')\n",
    "    max_accuracy, max_string = evaluate_feature([feature], X_train)\n",
    "    feature_acc.append(max_accuracy)\n",
    "    feature_strings.append(max_string)\n",
    "    \n",
    "normal_accuracy, _ = evaluate_feature([],X_train)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eefc45cb-8bcf-4d20-adf2-95522b27a18d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1531f224-7faa-4257-a33b-b15c3862fd72",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "\n",
    "all_features =  X_train.columns.tolist()\n",
    "feature_acc \n",
    "feature_strings \n",
    "print(feature_acc, normal_accuracy)\n",
    "\n",
    "plt.barh(all_features, ((np.array(feature_acc)-normal_accuracy)*100)) #0,len(all_features))\n",
    "plt.show()\n",
    "\n",
    "\n",
    "feature_acc = np.array(feature_acc)\n",
    "\n",
    "# remove all features that decrease the accuracy if they are included\n",
    "feature_usefull = (feature_acc-normal_accuracy) > 0 \n",
    "\n",
    "print(feature_acc, feature_usefull)\n",
    "\n",
    "\n",
    "\n",
    "feature =  [feat for usefull,feat in zip(feature_usefull,all_features) if   usefull]\n",
    "print(feature)\n",
    "max_accuracy, max_string = evaluate_feature(feature,X_train)\n",
    "print('\\n\\n',max_accuracy, max_string)\n",
    "\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbfbc748-b140-44dc-b53b-f5218e9cf439",
   "metadata": {},
   "source": [
    "# Dropping features iteratively:\n",
    "reducing features one by one \n",
    "it has been noticed, that simply dropping all features that impact the accuracy negatively does not yield a favorable result. It drops the accuracy significantly. Only keeping features that impact the accuracy negatively individually however increases the accuracy which is a bit perplexing. Now the strategy is to drop a single feature that impacts the performance the most in a negative direction and then see for the remaining features if there is one that can be removed. I don't expect this to result in a optimal feature combination but it can only improve and not worsen the resulting performance in terms of accuracy on the crossvalidation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1327f0cf-68d2-4fcf-8f3f-31cc77c9d1de",
   "metadata": {},
   "outputs": [],
   "source": [
    "some_features = all_features =  X_train.columns.tolist()\n",
    "old_accuracy = normal_accuracy\n",
    "new_accuracy = normal_accuracy\n",
    "new_model = ''\n",
    "old_model = ''\n",
    "last_feature_removed = ''\n",
    "\n",
    "done = False\n",
    "\n",
    "while(not done ):\n",
    "    old_accuracy = new_accuracy\n",
    "    old_model = new_model\n",
    "    feature_acc = []\n",
    "    feature_strings = []\n",
    "    for feature in some_features:\n",
    "        print(f'current Feature eliminated = {feature}')\n",
    "        max_accuracy, max_string = evaluate_feature([feature],X_train[some_features])\n",
    "        feature_acc.append(max_accuracy)\n",
    "        feature_strings.append(max_string)\n",
    "    ind_min = np.argmin(feature_acc) # find the feature that reduced accuracy the most\n",
    "    new_accuracy = np.max(feature_acc) # find the new maximum accuracy\n",
    "    new_model = feature_strings[np.argmax(feature_acc)]\n",
    "    print(f'new_accuracy = {new_accuracy}, old = {old_accuracy},accuracies = {feature_acc}')\n",
    "    if(new_accuracy >= old_accuracy): # if the new accuracy is better remove the next feature that negatively influences accuracy the most\n",
    "        print(f' the last feature removed was {last_feature_removed} , now {some_features[ind_min]} will be removed, accuracy was{old_accuracy} ,\\n features = {some_features}')\n",
    "        last_feature_removed = some_features[ind_min]\n",
    "        del some_features[ind_min]\n",
    "        print(f' the last feature')\n",
    "    else:\n",
    "        done = True\n",
    "        some_features.append(last_feature_removed)\n",
    "    \n",
    "\n",
    "print(f' The left over Features are: {some_features} , best accuracy: {old_accuracy}, for model: ')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "612f9005-6388-41e6-8d4f-44db17f31e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "print( set(x_data.columns.tolist()).difference(set(some_features)  ))\n",
    "\n",
    "print(len(x_data.columns.tolist()))\n",
    "\n",
    "print(len(some_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53b02106-1132-4ede-b787-5c08a903fdae",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = X_train.columns.tolist\n",
    "print(columns)\n",
    "print(f'current Feature eliminated = {feature}')\n",
    "max_accuracy, max_string = evaluate_feature(['Number of female actors'],X_train)\n",
    "print(max_accuracy)\n",
    "max_accuracy, max_string = evaluate_feature([],X_train)\n",
    "print(max_accuracy)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "015564ae-6a5d-4fba-825e-0f4780bff737",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train[['Difference in words lead and co-lead', 'Number of male actors']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40aee40e-04fb-4d21-a1ad-520a47639a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(y_data.values), np.sum(y_data.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f65e043-b406-4c4e-8067-500862a4504a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
